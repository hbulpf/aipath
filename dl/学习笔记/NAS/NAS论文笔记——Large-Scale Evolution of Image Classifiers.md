@[toc]

# 论文工作
论文对进化算法进行了改动，使其可以用于NAS(神经网络架构搜索)，算法对于计算资源要求较高。算法一开始从没有任何卷积的最简单的模型开始进化，与之前看过的论文不同的是，神经网络架构没有固定的网络深度（意味着搜索空间进一步扩大，算法运行时间长）

<br>

# 进化算法

<br>

## 算法过程简介
改进的进化算法主要有以下特点：

 1. 种群中的每个个体都有基因编码
 2. 种群中的每个个体都是训练好的神经网络架构，其适应度为该神经网络架构在验证集上的准确率
 3. 选择：使用锦标赛算法，每次随机选择两个个体，适应度较小的个体将从种群中移除
 4. 交配：从种群中选择两个适应度最高的神经网络架构作为父母，产生两个后代，分别与母亲和父亲的架构一致
 5. 变异：对产生的两个后代架构进行变异操作
 6. 训练新产生的后代，并将其在验证集上的准确率作为适应度函数

可以看到，大致步骤与之前看过的几篇论文基本一致，只是神经网络架构的搜索空间不同

<br>

## 基因编码
采用有向图表示形式表示神经网络架构的基因编码，具体如下：

 1. 有向图中的每个顶点表示特征图
 2. 边表示卷积操作或是直接映射
 3. 激活函数可以通过两种方式作用于顶点（特征图）：(1) BN+ReLU , (2) 线性激活函数，即不做任何操作

可以看到，并不是所有的特征图都会经过激活函数操作，一个顶点可以被多条边指向，每条边作用于原顶点后得到的特征图之间的空间分辨率和channel是不一样的，此时要将多个特征图合并为一个，具体做法如下：

 1. 随机选择一条边，将其作为直接连接，成为primary edge，其余边作为skip edge（联想残差结构）
 2. 所有的skip edge对应的特征图都reshape为primary edge对应的特征图
 3. 空间分辨率通过[最近邻插值](https://blog.csdn.net/willian0621/article/details/8685236)进行缩放
 4. channel通过padding（可能是添加新的特征图，但是特征图的中所有值为0）或是truncation（可能是采用1*1卷积进行变换）进行缩放

学习率也是基因编码的一部分

<br>

## 变异
产生的后代一定会进行变异，每次随机从提前定义好的变异操作集中随机选择一个变异操作，具体如下：

 1. 改变学习率
 2. 架构不发生任何改变，继续训练
 3. 放弃现有权重（后面会提到后代会继承父母的权重）
 4. 插入卷积层(卷积核大小 3x3， 步长随机1或2，通道数和输入通道数一样， 最后在随机决定是否加上 BN和 ReLU，插入位置随机
 5. 移除卷积层
 6. 改变卷积核的步伐数，只能是2的幂
 7. 随机选择一个卷积，改变卷积的通道数
 8. 改变卷积核的大小，随机选择水平或是垂直方向，随机选择卷积核，改变数值随机
 9. 添加skip连接
 10. 移除skip连接
 11. 插入一对一层(卷积核大小 1x1，步长随机1或2，通道数和输入通道数一样，最后在随机决定是否加上BN和ReLU)

<br>

## 初始化
所有的个体都从学习率为0.1的最简单的框架开始，每个个体仅有一个输入层、输出层、全局池化层，如下：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190712100934205.png)

<br>

## 权重继承
考虑到算法运行时间，对于每一个框架，只会进行25600次迭代，此时网络并未完全收敛，但是让每个网络都收敛需要大量的运行时间和算力，因此，新个体允许继承父母的权重，接着对其进行变异操作，通过变异操作后，新个体的权重将完全或是部分等于父母（如果网络的某个部分发生了结构改变，那么该部分的权重将被放弃）

<br>

# 实验及其结果

实验发现的网络架构例子：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190712145847587.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RoYWl1ZGE=,size_16,color_FFFFFF,t_70)
与之前看过的文献不同的是，该算法并没有将小数据集上发现的网络架构直接应用于大数据集，而是分别在小数据集和大数据集上运行算法，在CIFAR-10和CIFAR-100数据集上运行的算法结果如下，论文应该是将算法发现的最优秀的网络架构进行了充分的迭代训练后在进行比较的
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190712150036647.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RoYWl1ZGE=,size_16,color_FFFFFF,t_70)
可以看到，进化算法发现的网络架构性能马马虎虎，通过同时运行5个算法，论文比对了禁止权重继承对于算法的影响，如下图：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190712150328615.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RoYWl1ZGE=,size_16,color_FFFFFF,t_70)
 由此可见，权重继承可以提高算法的运行结果

<br>

## 影响算法运行的两个超参数
论文作者观察到种群大小以及每个个体的训练轮数对于算法的运行结果有较大的影响，种群大小的值设置的越大，越有利于探索搜索空间，找到的网络架构也更加优秀，训练轮数越多，算法找到的模型的表现越优异，如果训练轮数小或是种群大小过小，可能会陷入局部最小值，具体运行结果如下：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190712151450166.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RoYWl1ZGE=,size_16,color_FFFFFF,t_70)
