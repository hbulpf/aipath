@[toc]

# 前言
卷积神经网络在图像领域性能十分卓越，不仅可应用于图像识别，也可应用于目标检测与语义分割。目标检测与语义分割都需要定位目标在图像中的位置，而卷积神经网络在这两类任务中表现优异，是否意味着卷积神经网络可以编码目标的绝对位置（目标在图像中的位置，而不是目标相对于图像中的其他事物的位置）信息呢？

2020 ICLR的文章《how much position information do convolutional neural networks encode?》，通过实验验证了卷积神经网络可以编码目标的绝对位置信息，并且更进一步探究了卷积神经网络能编码目标的位置信息的原因，这将有助于我们设计针对目标检测与语义分割的卷积神经网络结构。

<br>

# 猜想
如下图所示，目标位于图像的正中间位置，当我们将图像进行裁剪，使得目标位于图像的右侧时，卷积神经网络的检测点（原文为detecting saliency）从图像的正中间移动到了图像的右侧，作者因此做出了一个假设：**卷积神经网络可以编码目标在图像中的绝对位置，即feature vector\feature map中含有目标的绝对位置信息**。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200401103342221.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RoYWl1ZGE=,size_16,color_FFFFFF,t_70#pic_center)

有许多可视化技术验证了卷积神经网络可以学习目标具有的特征（例如猪的鼻子长什么样，眼睛长什么样等），例如grad-cam、cam等（这两类算法可以查看我的[博客](https://blog.csdn.net/dhaiuda/article/details/102937760)），这类可视化技术可以解释卷积神经网络分类的依据，但是不能解释为什么卷积神经网络可以定位到类别相关的区域，这篇文章将此归因为zero-padding，zero-padding将有助于卷积神经网络编码目标在图像中的位置信息，但是文章没有更进一步解释为什么zero-padding有助于卷积神经网络编码目标的位置信息。


<br>

# 实验

<br>

## 实验思路

假设我们存在一种可以反映位置关系的label，记为**position map**，如果我们能建立**feature map/feature vector**到$Y$的映射，将表明**feature map/feature vector**与$Y$之间存在某种规律，即**feature map/feature vector**中的数值含有位置信息的规律，而**feature map/feature vector**是由卷积神经网络提取的，这表明卷积神经网络可以提取位置信息。

**映射关系可以通过神经网络建立，那么如何得到可以反映位置关系的position map呢？**

作者设立了五类可以反映位置关系的**position map**，分别记为$H、V、G、HS、VS$。$H$中的像素值表示该位置离图像左边缘的距离，$V$中的像素值表示该位置离图像上边缘的距离，这两类图像可以证明卷积神经网络是否可以提取两个维度上的位置信息。$G$由高斯过滤器得到，论文没有具体解释如何得到$G、HS、VS$，这三类图像可以证明卷积神经网络是否可以提取两个维度上的位置信息，这五类label与图像的内容无关，因此输入图像可以是任何类别的图像。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200402100526611.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RoYWl1ZGE=,size_16,color_FFFFFF,t_70#pic_center)
上图中，第一行表示输入图像，第二行表示label，注意到作者添加了black、white、noise三类图像，这三类图像通常不含有图像的语义信息，可以验证在没有语义信息的前提下，卷积神经网络能否编码位置信息。

<br>

## 网络结构——position encoding network
**position encoding network**的网络结构如下，该网络由**Encoder**和**Position Encoding Module**两部分组成。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200402102100303.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RoYWl1ZGE=,size_16,color_FFFFFF,t_70#pic_center)
<br>

如上图所示，Encoder即上图中的$f_{enc}$，是一个**参数固定**的特征提取器，**不参与训练**，上图的$f_{enc}$含有五个特征提取模块，五个特征提取模块提取的feature map记为$(f_{pos}^1,f_{pos}^2,f_{pos}^3,f_{pos}^4,f_{pos}^5)$。

Position Encoding Module将$(f_{pos}^1,f_{pos}^2,f_{pos}^3,f_{pos}^4,f_{pos}^5)$作为输入，经过$\Gamma_{pos}$处理，输出为**position map**，$\Gamma_{pos}$首先使用双线性插值，让$(f_{pos}^1,f_{pos}^2,f_{pos}^3,f_{pos}^4,f_{pos}^5)$中的feature map空间分辨率一致，接着将其concat，经过一层空间分辨率为k x k的卷积核$W_{pos}^c$，得到**position map**，$W_{pos}^c$**可被训练**。

<br>

## 评价指标
将**position encoding network**输出的feature map上采样，使其大小与**position map**一致，接着计算像素值之间均方差（MAE），计算公式如下：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200402152347847.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RoYWl1ZGE=,size_16,color_FFFFFF,t_70#pic_center)
$n$表示像素个数之和，$x_i$与$y_i$分别表示feature map与**position map**在同一位置上的像素值，MAE数值越小，表明feature map与**position map**之间的差距越小

除此之外，论文还将使用斯皮尔曼相关系数（SCP）度量feature map与**position map**之间的相关性，SCP越接近于1，表明两个变量之间的相关性越强，变化趋势的方向以及程度越一致。

<br>

## 实验结果
论文做的实验比较多，这里截取两个比较有趣的部分。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200402153528510.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RoYWl1ZGE=,size_16,color_FFFFFF,t_70#pic_center)
PosENet：只使用Position Encoding Module
VGG：使用预训练的VGG+Position Encoding Module
ResNet：使用预训练的ResNet+Position Encoding Module

单独使用PosENet，效果很糟，但是加入VGG与ResNet，结果会变好，这说明ResNet与VGG提取的feature map是含有位置信息的。

![在这里插入图片描述](https://img-blog.csdnimg.cn/2020040216034728.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RoYWl1ZGE=,size_16,color_FFFFFF,t_70#pic_center)
上图显示了zero Padding对SCP与MAE两个指标的联系，可以看到，添加了zero padding后，SCP越大、MAE越小，这说明zero Padding与位置信息的提取有一定关系。论文也探究了zero padding在目标检测与语义分割任务中的表现，结果如下，可见zero padding对位置信息的提取尤为重要。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200402160720623.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RoYWl1ZGE=,size_16,color_FFFFFF,t_70#pic_center)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200404200239339.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RoYWl1ZGE=,size_16,color_FFFFFF,t_70#pic_center)
